---
title: "Outpatient Psychiatry In-Basket Workload Analysis"
subtitle: "A Comprehensive Analysis of Epic Signal Analytics Data"
author: "BMIN 5070 Research Project"
date: "`r Sys.Date()`"
format: 
  html:
    theme: cosmo
    toc: true
    toc-depth: 3
    number-sections: true
    fig-cap-location: top
    fig-dpi: 300
    css: |
      body { 
        font-family: "Times New Roman", serif;
        line-height: 1.6;
        max-width: 1200px;
        margin: 0 auto;
        padding: 20px;
      }
      .main-container {
        max-width: 1200px;
        margin: 0 auto;
      }
      h1, h2, h3, h4, h5, h6 {
        color: #2c3e50;
        margin-top: 2em;
        margin-bottom: 1em;
      }
      table {
        font-size: 0.9em;
        margin: 1em 0;
      }
      .kable-table {
        margin: 1em 0;
      }
---

```{r setup, include=FALSE}
# Global options
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.align = "center",
  fig.width = 7,
  fig.height = 5,
  dpi = 300,
  out.width = "100%"
)

# Load required libraries
library(readxl)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(janitor)
library(ggplot2)
library(scales)
library(knitr)
library(kableExtra)
library(forcats)
library(tibble)
library(patchwork)
library(viridis)
library(gridExtra)
```

# Executive Summary

This comprehensive analysis examines Epic in-basket messaging workload across **64 healthcare providers** in the Department of Psychiatry at Penn Medicine during the period of **July 2024 – June 2025**. The study describes workload disparities and patterns in provider messaging behavior.

## Key Findings

- **160× variation** in in-basket workload across providers
- **1,941.2 total hours** over 12-month period (1.04 FTE equivalent)
- **Top 10% of providers** handle 33% of total messaging burden
- **$335,828 potential annual revenue loss** from in-basket work (extrapolated)
- **121.8% ROI** calculated for workload redistribution scenarios
- **Additional appointment capacity** through workload optimization
- **After-hours work reduction** potential through provider offloading

## Analysis Overview

This report presents a descriptive analysis of Epic in-basket messaging patterns across the Outpatient Psychiatry Clinic (OPC) located at 3535 Market St, second floor, within the Department of Psychiatry. The findings describe workload distribution, provider characteristics, and financial metrics without prescribing specific actions or interventions.

# Methods

## Data Source

Data was extracted from **Epic Signal Analytics**, the official reporting system for Penn Medicine Health System. The dataset includes comprehensive metrics on provider activity, messaging workload, and system utilization from the Outpatient Psychiatry Clinic (OPC) located at 3535 Market St, second floor.

## Study Population

All providers with >=30 days of system activity during the 12-month observation period (n=64):
- **Attending Psychiatrists** (MD): n=32 (50%)
- **Nurse Practitioners** (NP): n=19 (30%)  
- **Residents/Fellows** (RF): n=13 (20%)

## Data Processing

```{r data-processing, echo=TRUE, eval=FALSE}
# Load and process raw data
messages <- read_excel("epic-signal-analytics-data.xlsx", sheet = "Messages")
time <- read_excel("epic-signal-analytics-data.xlsx", sheet = "Time")
raw <- bind_rows(messages, time)

# Filter relevant metrics and clean data
filtered <- raw |>
  filter(Metric %in% c(
    "Count Of Scheduled Days",
    "Scheduled Hours per Day", 
    "Count Of Appointments",
    "Count Of Minutes In The System",
    "Count Of In Basket Minutes",
    "Count Of Patient Call Messages Recieved",
    "Count Of Patient Medical Advice Requests Messages Recieved",
    "Count Of Result Messages Recieved",
    "Count Of RX Auth Messages Recieved",
    "Average Days Until Patient Call Messages Marked Done",
    "Average Days Until Patient Medical Advice Request Message Marked Done",
    "Average Days Until Result Message Marked Done",
    "Average Days Until RX Auth Message Marked Done",
    "Count Of Minutes Active Outside Scheduled Time (30 Min Buffer)",
    "Count Of Saturday Minutes",
    "Count Of Sunday Minutes"
  ))
```

## Statistical Analysis

- **Descriptive Statistics**: Means, medians, standard deviations by provider type
- **Workload Distribution**: Lorenz curves and Gini coefficients for inequality analysis
- **Correlation Analysis**: Relationships between workload metrics and performance indicators
- **Financial Metrics**: Cost calculations and resource utilization analysis

# Results

## Overall Department Statistics

```{r load-data}
# Load processed data
final <- readRDS("data/processed/04-final-analysis-dataset.rds")
```

```{r overall-stats}
# Calculate overall department statistics
overall_stats <- final |>
  summarise(
    total_providers = n(),
    total_inbasket_hours = sum(inbasket_hours, na.rm = TRUE),
    total_messages = sum(messages, na.rm = TRUE),
    total_appointments = sum(appointments, na.rm = TRUE),
    total_system_hours = sum(system_hours, na.rm = TRUE),
    total_afterhours = sum(afterhours, na.rm = TRUE),
    mean_inbasket_hours = mean(inbasket_hours, na.rm = TRUE),
    median_inbasket_hours = median(inbasket_hours, na.rm = TRUE),
    sd_inbasket_hours = sd(inbasket_hours, na.rm = TRUE),
    min_inbasket_hours = min(inbasket_hours, na.rm = TRUE),
    max_inbasket_hours = max(inbasket_hours, na.rm = TRUE),
    variation_ratio = max_inbasket_hours / min_inbasket_hours,
    fte_equivalent = total_inbasket_hours / (40 * 52 * 0.9),
    revenue_lost = total_inbasket_hours * 173
  )

# Create summary table
overall_table <- data.frame(
  Metric = c(
    "Total Providers",
    "Total In-Basket Hours", 
    "Total Messages",
    "Total Appointments",
    "Total System Hours",
    "Total After-Hours Work",
    "Mean In-Basket Hours",
    "Median In-Basket Hours",
    "Standard Deviation",
    "Minimum In-Basket Hours",
    "Maximum In-Basket Hours",
    "Workload Variation Ratio",
    "FTE Equivalent",
    "Revenue Lost"
  ),
  Value = c(
    paste0(overall_stats$total_providers, " providers"),
    paste0(round(overall_stats$total_inbasket_hours, 1), " hours"),
    paste0(overall_stats$total_messages, " messages"),
    paste0(overall_stats$total_appointments, " appointments"),
    paste0(round(overall_stats$total_system_hours, 1), " hours"),
    paste0(round(overall_stats$total_afterhours, 1), " hours"),
    paste0(round(overall_stats$mean_inbasket_hours, 1), " hours"),
    paste0(round(overall_stats$median_inbasket_hours, 1), " hours"),
    paste0(round(overall_stats$sd_inbasket_hours, 1), " hours"),
    paste0(round(overall_stats$min_inbasket_hours, 3), " hours"),
    paste0(round(overall_stats$max_inbasket_hours, 1), " hours"),
    paste0(round(overall_stats$variation_ratio, 0), "×"),
    paste0(round(overall_stats$fte_equivalent, 2), " FTE"),
    paste0("$", format(overall_stats$revenue_lost, big.mark = ","))
  )
)

kable(overall_table, 
      caption = "Overall Department Statistics (July 2024 – June 2025)",
      col.names = c("Metric", "Value")) |>
  kable_styling(latex_options = c("hold_position", "scale_down"))
```

## Provider Type Analysis

```{r provider-type-analysis}
# Provider type comprehensive analysis
provider_type_analysis <- final |>
  group_by(type) |>
  summarise(
    n = n(),
    percentage = n() / nrow(final) * 100,
    mean_inbasket_hours = mean(inbasket_hours, na.rm = TRUE),
    median_inbasket_hours = median(inbasket_hours, na.rm = TRUE),
    mean_messages = mean(messages, na.rm = TRUE),
    mean_response_time = mean(avg_dummd, na.rm = TRUE),
    mean_appointments = mean(appointments, na.rm = TRUE),
    mean_system_hours = mean(system_hours, na.rm = TRUE),
    mean_afterhours = mean(afterhours, na.rm = TRUE),
    .groups = 'drop'
  ) |>
  mutate(
    type_label = case_when(
      type == 'MD' ~ 'Attending Psychiatrist',
      type == 'NP' ~ 'Nurse Practitioner',
      type == 'RF' ~ 'Resident/Fellow'
    )
  )

# Create provider type summary table
provider_table <- provider_type_analysis |>
  select(
    "Provider Type" = type_label,
    "Count" = n,
    "% of Total" = percentage,
    "Mean In-Basket Hours" = mean_inbasket_hours,
    "Median In-Basket Hours" = median_inbasket_hours,
    "Mean Messages" = mean_messages,
    "Mean Response Time (days)" = mean_response_time,
    "Mean Appointments" = mean_appointments,
    "Mean System Hours" = mean_system_hours,
    "Mean After-Hours" = mean_afterhours
  ) |>
  mutate(
    "% of Total" = paste0(round(`% of Total`, 1), "%"),
    "Mean In-Basket Hours" = round(`Mean In-Basket Hours`, 1),
    "Median In-Basket Hours" = round(`Median In-Basket Hours`, 1),
    "Mean Messages" = round(`Mean Messages`, 0),
    "Mean Response Time (days)" = round(`Mean Response Time (days)`, 2),
    "Mean Appointments" = round(`Mean Appointments`, 0),
    "Mean System Hours" = round(`Mean System Hours`, 0),
    "Mean After-Hours" = round(`Mean After-Hours`, 1)
  )

kable(provider_table,
      caption = "Provider Type Analysis",
      digits = 2) |>
  kable_styling(latex_options = c("hold_position", "scale_down"))
```

## Workload Distribution Analysis

```{r workload-distribution}
# Create workload distribution plot
p_workload <- ggplot(final, aes(x = reorder(id, inbasket_hours), y = inbasket_hours)) +
  geom_col(aes(fill = type), alpha = 0.8) +
  geom_hline(yintercept = median(final$inbasket_hours, na.rm = TRUE), 
             linetype = 'dashed', color = '#E31A1C', linewidth = 1) +
  scale_fill_manual(
    name = 'Provider Type',
    values = c('MD' = '#990000', 'NP' = '#011F5B', 'RF' = '#82AFD3'),
    labels = c('MD' = 'Attending Psychiatrist', 'NP' = 'Nurse Practitioner', 'RF' = 'Resident/Fellow')
  ) +
  scale_y_continuous(labels = scales::number_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.1))) +
  labs(
    title = 'Provider In-Basket Workload Distribution',
    subtitle = paste0('160× variation in workload (', round(min(final$inbasket_hours[final$inbasket_hours >= 1], na.rm = TRUE), 1), ' to ', round(max(final$inbasket_hours, na.rm = TRUE), 1), ' hours)'),
    x = 'Provider (Ranked by In-Basket Hours)',
    y = 'In-Basket Hours',
    caption = 'Red dashed line indicates median (23.8 hours)'
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(size = 14, face = 'bold'),
    plot.subtitle = element_text(size = 11, color = 'gray50'),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    legend.position = 'bottom',
    plot.caption = element_text(size = 9, color = 'gray60'),
    plot.margin = margin(15, 15, 15, 15)
  )

print(p_workload)
```

## Workload Inequality Analysis

```{r lorenz-curve}
# Create Lorenz curve data
lorenz_data <- final |>
  select(id, inbasket_hours) |>
  mutate(inbasket_hours = coalesce(inbasket_hours, 0)) |>
  arrange(inbasket_hours) |>
  mutate(
    cum_hours = cumsum(inbasket_hours),
    tot_hours = sum(inbasket_hours),
    cum_hours_pct = ifelse(tot_hours > 0, cum_hours / tot_hours, 0),
    cum_prov = row_number(),
    tot_prov = n(),
    cum_prov_pct = cum_prov / tot_prov
  )

# Calculate Gini coefficient
gini_coef <- lorenz_data |>
  summarise(
    gini = ifelse(tot_hours[1] > 0, 1 - mean(lag(cum_hours_pct, default = 0) + cum_hours_pct), NA_real_)
  ) |>
  pull(gini)

lorenz_curve <- bind_rows(
  tibble(cum_prov_pct = 0, cum_hours_pct = 0),
  lorenz_data |> select(cum_prov_pct, cum_hours_pct)
)

# Create Lorenz curve plot
p_lorenz <- ggplot(lorenz_curve, aes(cum_prov_pct, cum_hours_pct)) +
  geom_area(aes(y = cum_prov_pct), fill = 'gray90', alpha = 0.5) +
  geom_line(linewidth = 1.2, color = '#2C7FB8') +
  geom_abline(slope = 1, intercept = 0, linetype = 'dashed', color = '#E31A1C', linewidth = 1) +
  annotate('text', x = 0.15, y = 0.95,
           label = paste0('Gini Coefficient = ', round(gini_coef, 3)),
           size = 5, color = 'black', fontface = 'bold', hjust = 0) +
  annotate('text', x = 0.85, y = 0.85,
           label = 'Perfect Equality',
           size = 4, color = '#E31A1C', fontface = 'bold', hjust = 0) +
  annotate('text', x = 0.5, y = 0.1,
           label = paste0('Bottom 50% of providers\nhandle only ', round(lorenz_data$cum_hours_pct[lorenz_data$cum_prov_pct == 0.5], 1) * 100, '% of workload'),
           size = 4, color = 'black', hjust = 0.5, fontface = 'bold') +
  scale_x_continuous(labels = scales::percent_format(), 
                     expand = expansion(mult = c(0.02, 0.02))) +
  scale_y_continuous(labels = scales::percent_format(), 
                     expand = expansion(mult = c(0.02, 0.02))) +
  labs(
    title = 'Lorenz Curve: Workload Inequality Analysis',
    subtitle = paste0('Distribution of in-basket hours across ', nrow(final), ' providers'),
    x = 'Cumulative Share of Providers',
    y = 'Cumulative Share of In-Basket Hours',
    caption = 'Red dashed line represents perfect equality; blue curve shows actual distribution'
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(size = 14, face = 'bold'),
    plot.subtitle = element_text(size = 11, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 9, color = 'gray60'),
    plot.margin = margin(15, 15, 15, 15)
  )

print(p_lorenz)
```

## Message Type Analysis

```{r message-analysis}
# Message type comprehensive analysis
message_type_summary <- final |>
  summarise(
    medical_advice = sum(messages_mar, na.rm = TRUE),
    patient_calls = sum(messages_pc, na.rm = TRUE),
    results = sum(messages_res, na.rm = TRUE),
    prescriptions = sum(messages_rxa, na.rm = TRUE),
    total = sum(messages, na.rm = TRUE)
  )

message_type_analysis <- message_type_summary |>
  pivot_longer(everything(), names_to = 'message_type', values_to = 'count') |>
  mutate(
    percentage = count / message_type_summary$total * 100,
    message_label = case_when(
      message_type == 'medical_advice' ~ 'Medical Advice Requests',
      message_type == 'patient_calls' ~ 'Patient Call Messages',
      message_type == 'results' ~ 'Result Messages',
      message_type == 'prescriptions' ~ 'Prescription Authorization',
      message_type == 'total' ~ 'Total Messages'
    )
  )

# Create message type plot
p_messages <- ggplot(message_type_analysis |> filter(message_type != 'total'), 
                     aes(x = reorder(message_label, count), y = count)) +
  geom_col(aes(fill = message_type), alpha = 0.8, width = 0.6) +
  geom_text(aes(label = paste0(scales::comma(count), '\n(', round(percentage, 1), '%)')), 
            hjust = -0.1, size = 3.5, fontface = 'bold') +
  scale_fill_manual(
    values = c('medical_advice' = '#33A02C', 'patient_calls' = '#FF7F00', 
               'results' = '#E31A1C', 'prescriptions' = '#6A3D9A'),
    guide = 'none'
  ) +
  scale_y_continuous(labels = scales::comma_format(), expand = expansion(mult = c(0, 0.1))) +
  coord_flip() +
  labs(
    title = 'Total Messages by Type',
    subtitle = paste0('Annual message distribution (Total: ', scales::comma(sum(message_type_analysis$count[message_type_analysis$message_type != 'total'])), ')'),
    x = 'Message Type',
    y = 'Total Messages',
    caption = 'Medical advice requests are the most common message type'
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(size = 14, face = 'bold'),
    plot.subtitle = element_text(size = 11, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 9, color = 'gray60'),
    plot.margin = margin(15, 15, 15, 15)
  )

print(p_messages)
```

## Correlation Analysis

```{r correlation-analysis}
# Correlation matrix
cor_vars <- c(
  "appointments", "schedule_hours", "system_hours", "inbasket_hours", "afterhours",
  "messages", "messages_pc", "messages_mar", "messages_res", "messages_rxa",
  "avg_dummd", "avg_dummd_pc", "avg_dummd_mar", "avg_dummd_res", "avg_dummd_rxa"
)

cor_matrix <- final |>
  select(all_of(cor_vars)) |>
  mutate(across(everything(), ~ coalesce(.x, 0))) |>
  cor(use = "pairwise.complete.obs")

# Create correlation heatmap
cor_df <- expand.grid(Var1 = rownames(cor_matrix), Var2 = colnames(cor_matrix)) |>
  mutate(
    correlation = as.vector(cor_matrix),
    Var1 = factor(Var1, levels = rev(rownames(cor_matrix))),
    Var2 = factor(Var2, levels = colnames(cor_matrix))
  )

p_corr <- ggplot(cor_df, aes(Var2, Var1, fill = correlation)) +
  geom_tile(color = 'white', linewidth = 1) +
  geom_text(aes(label = round(correlation, 2), color = abs(correlation) > 0.3), 
            size = 3, fontface = 'bold') +
  scale_color_manual(values = c('TRUE' = 'white', 'FALSE' = 'black'), guide = 'none') +
  scale_fill_gradient2(
    low = '#D73027', mid = 'white', high = '#1A9850',
    midpoint = 0, limit = c(-1, 1), space = 'Lab',
    name = 'Correlation',
    guide = guide_colorbar(barwidth = 15, barheight = 1)
  ) +
  scale_x_discrete(
    labels = c('appointments' = 'Appointments', 'schedule_hours' = 'Schedule\nHours', 
               'system_hours' = 'System\nHours', 'inbasket_hours' = 'In-Basket\nHours',
               'afterhours' = 'After-Hours', 'messages' = 'Total\nMessages',
               'messages_pc' = 'Patient\nCalls', 'messages_mar' = 'Med\nAdvice',
               'messages_res' = 'Results', 'messages_rxa' = 'Rx\nAuth',
               'avg_dummd' = 'Response\nTime', 'avg_dummd_pc' = 'PC Response\nTime',
               'avg_dummd_mar' = 'MAR Response\nTime', 'avg_dummd_res' = 'Results Response\nTime',
               'avg_dummd_rxa' = 'Rx Response\nTime')
  ) +
  scale_y_discrete(
    labels = c('appointments' = 'Appointments', 'schedule_hours' = 'Schedule Hours', 
               'system_hours' = 'System Hours', 'inbasket_hours' = 'In-Basket Hours',
               'afterhours' = 'After-Hours Work', 'messages' = 'Total Messages',
               'messages_pc' = 'Patient Calls', 'messages_mar' = 'Medical Advice',
               'messages_res' = 'Results', 'messages_rxa' = 'Rx Authorization',
               'avg_dummd' = 'Response Time', 'avg_dummd_pc' = 'PC Response Time',
               'avg_dummd_mar' = 'MAR Response Time', 'avg_dummd_res' = 'Results Response Time',
               'avg_dummd_rxa' = 'Rx Response Time')
  ) +
  labs(
    title = 'Correlation Matrix: Key Workload Metrics',
    subtitle = 'Relationships between workload and performance indicators',
    x = NULL, y = NULL,
    caption = 'Red = negative correlation, Green = positive correlation; values closer to ±1 indicate stronger relationships'
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(size = 14, face = 'bold'),
    plot.subtitle = element_text(size = 11, color = 'gray50'),
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    panel.grid = element_blank(),
    legend.position = 'bottom',
    plot.caption = element_text(size = 9, color = 'gray60'),
    plot.margin = margin(15, 15, 15, 15)
  )

print(p_corr)
```

## Workload Share Distribution Analysis

```{r workload-share-analysis}
# Workload share distribution
reach_n <- function(cs, thr) { i <- which(cs >= thr)[1]; if (is.na(i)) length(cs) else i }

workload_share_table <- final |>
  select(id, ends_with("_share")) |>
  mutate(across(-id, ~coalesce(.x, 0))) |>
  pivot_longer(-id, names_to = "metric", values_to = "share") |>
  group_by(metric) |>
  arrange(metric, desc(share)) |>
  mutate(cs = cumsum(share), tot = sum(share)) |>
  summarise(
    n_providers = n(),
    n_top25 = reach_n(cs, 0.25 * tot),
    n_top50 = reach_n(cs, 0.50 * tot),
    n_top75 = reach_n(cs, 0.75 * tot),
    n_top90 = reach_n(cs, 0.90 * tot),
    n_top95 = reach_n(cs, 0.95 * tot),
    n_top99 = reach_n(cs, 0.99 * tot),
    .groups = "drop"
  ) |>
  transmute(
    metric = case_when(
      metric == "appointments_share" ~ "Appointments",
      metric == "inbasket_hours_share" ~ "In-Basket Hours",
      metric == "schedule_hours_share" ~ "Schedule Hours",
      metric == "system_hours_share" ~ "System Hours",
      metric == "afterhours_share" ~ "After-Hours Work"
    ),
    `Top 25%` = sprintf("%d (%.1f%%)", n_top25, 100 * n_top25 / n_providers),
    `Top 50%` = sprintf("%d (%.1f%%)", n_top50, 100 * n_top50 / n_providers),
    `Top 75%` = sprintf("%d (%.1f%%)", n_top75, 100 * n_top75 / n_providers),
    `Top 90%` = sprintf("%d (%.1f%%)", n_top90, 100 * n_top90 / n_providers),
    `Top 95%` = sprintf("%d (%.1f%%)", n_top95, 100 * n_top95 / n_providers),
    `Top 99%` = sprintf("%d (%.1f%%)", n_top99, 100 * n_top99 / n_providers),
  ) |>
  arrange(metric)

kable(workload_share_table,
      caption = "Workload Share Distribution",
      col.names = c("Workload Metric", "Top 25%", "Top 50%", "Top 75%", "Top 90%", "Top 95%", "Top 99%")) |>
  kable_styling(latex_options = c("hold_position", "scale_down"))
```

## Top 10 Providers Analysis

```{r top-10-analysis}
# Top 10 providers analysis
top_10_analysis <- final |>
  arrange(desc(inbasket_hours)) |>
  head(10) |>
  select(id, type, inbasket_hours, messages, appointments, avg_dummd, afterhours) |>
  mutate(
    type_label = case_when(
      type == 'MD' ~ 'Attending',
      type == 'NP' ~ 'Nurse Practitioner',
      type == 'RF' ~ 'Resident/Fellow'
    ),
    rank = row_number()
  )

# Create top 10 table
top_10_table <- top_10_analysis |>
  select(
    "Rank" = rank,
    "Provider ID" = id,
    "Provider Type" = type_label,
    "In-Basket Hours" = inbasket_hours,
    "Total Messages" = messages,
    "Appointments" = appointments,
    "Response Time (days)" = avg_dummd,
    "After-Hours Work" = afterhours
  ) |>
  mutate(
    "In-Basket Hours" = round(`In-Basket Hours`, 1),
    "Response Time (days)" = round(`Response Time (days)`, 1),
    "After-Hours Work" = round(`After-Hours Work`, 1)
  )

kable(top_10_table,
      caption = "Top 10 Providers by In-Basket Workload",
      digits = 1) |>
  kable_styling(latex_options = c("hold_position", "scale_down"))
```

## Financial Impact Analysis

```{r financial-analysis}
# Financial calculations
fte_denominator <- 40 * 52 * 0.9  # 1,872 hours
rate_per_hour <- 173
nursing_rate <- 78

# Overall department financial impact
total_hours <- sum(final$inbasket_hours, na.rm = TRUE)
fte_equivalent <- total_hours / fte_denominator
revenue_lost <- total_hours * rate_per_hour

# Top 10 providers financial analysis
top_10_hours <- sum(top_10_analysis$inbasket_hours, na.rm = TRUE)
top_10_messages <- sum(top_10_analysis$messages, na.rm = TRUE)
top_10_fte <- top_10_hours / fte_denominator
top_10_revenue_recovery <- top_10_hours * rate_per_hour

# Pilot program cost analysis
nursing_hours <- top_10_hours
nursing_cost <- nursing_hours * nursing_rate
provider_oversight_cost <- 0.5 * fte_denominator * rate_per_hour
it_support_cost <- 0.25 * fte_denominator * rate_per_hour
total_intervention_cost <- nursing_cost + provider_oversight_cost + it_support_cost

# Net financial impact
net_annual_benefit <- top_10_revenue_recovery - total_intervention_cost
roi_percentage <- (net_annual_benefit / total_intervention_cost) * 100

# Create financial summary table
financial_table <- data.frame(
  Category = c(
    "Overall Department",
    "",
    "Total In-Basket Hours",
    "FTE Equivalent",
    "Revenue Lost",
    "",
    "Top 10 Providers (Pilot Target)",
    "",
    "Provider Count",
    "Total Hours",
    "Total Messages",
    "FTE Equivalent",
    "Revenue Recovery Potential",
    "",
    "Pilot Program Costs",
    "",
    "Nursing Support (2 FTE)",
    "Provider Oversight (0.5 FTE)",
    "IT Support (0.25 FTE)",
    "Total Intervention Cost",
    "",
    "Net Financial Impact",
    "",
    "Revenue Recovery",
    "Total Costs",
    "Net Annual Benefit",
    "Return on Investment"
  ),
  Value = c(
    "",
    "",
    paste0(round(total_hours, 1), " hours"),
    paste0(round(fte_equivalent, 2), " FTE"),
    paste0("$", format(revenue_lost, big.mark = ",")),
    "",
    "",
    "",
    paste0(nrow(top_10_analysis), " providers"),
    paste0(round(top_10_hours, 1), " hours"),
    paste0(top_10_messages, " messages"),
    paste0(round(top_10_fte, 2), " FTE"),
    paste0("$", format(top_10_revenue_recovery, big.mark = ",")),
    "",
    "",
    "",
    paste0("$", format(nursing_cost, big.mark = ",")),
    paste0("$", format(provider_oversight_cost, big.mark = ",")),
    paste0("$", format(it_support_cost, big.mark = ",")),
    paste0("$", format(total_intervention_cost, big.mark = ",")),
    "",
    "",
    "",
    paste0("$", format(top_10_revenue_recovery, big.mark = ",")),
    paste0("$", format(total_intervention_cost, big.mark = ",")),
    paste0("$", format(net_annual_benefit, big.mark = ",")),
    paste0(round(roi_percentage, 1), "%")
  )
)

kable(financial_table,
      caption = "Financial Impact Analysis",
      col.names = c("Category", "Value")) |>
  kable_styling(latex_options = c("hold_position")) |>
  row_spec(c(1, 6, 7, 14, 15, 22), bold = TRUE, background = "#f0f0f0")
```

## Cumulative Impact Analysis

```{r cumulative-impact}
# Create cumulative impact analysis
ranked <- final |>
  arrange(desc(inbasket_hours)) |>
  mutate(
    rank = row_number(),
    cum_hours = cumsum(inbasket_hours),
    cum_messages = cumsum(messages),
    cum_appointments = cumsum(appointments)
  )

# Calculate metrics - using 30-minute appointments (2 appointments per hour)
throughput_per_hour <- 2  # 30-minute appointments = 2 appointments per hour

# Create cumulative data frame
cum_df <- ranked |>
  mutate(
    fte_freed = cum_hours / fte_denominator,
    revenue_recovered = cum_hours * rate_per_hour,
    added_appointments = cum_hours * throughput_per_hour,
    afterhours_remaining = sum(final$afterhours, na.rm = TRUE) - cumsum(pmin(inbasket_hours, afterhours))
  ) |>
  select(rank, fte_freed, revenue_recovered, added_appointments, afterhours_remaining)

# Create milestone points every 5 providers
milestones <- cum_df |>
  filter(rank %% 5 == 0 | rank == 1 | rank == nrow(cum_df))

# Create cumulative impact plots
p1 <- ggplot(cum_df, aes(x = rank)) +
  geom_area(aes(y = fte_freed), fill = '#2C7FB8', alpha = 0.3) +
  geom_line(aes(y = fte_freed), color = '#2C7FB8', linewidth = 1.2) +
  geom_point(data = milestones, aes(y = fte_freed), color = '#2C7FB8', size = 3) +
  scale_x_continuous(breaks = seq(0, 60, 10), limits = c(0, 64)) +
  scale_y_continuous(breaks = seq(0, 1.5, 0.25), labels = scales::number_format(accuracy = 0.01)) +
  labs(
    title = 'Cumulative FTE Freed',
    subtitle = 'Provider time recovery through workload redistribution',
    x = 'Top-k Providers Offloaded',
    y = 'FTE Equivalent Freed',
    caption = '1 FTE = 1,872 hours/year'
  ) +
  theme_minimal(base_size = 10) +
  theme(
    plot.title = element_text(size = 11, face = 'bold'),
    plot.subtitle = element_text(size = 9, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 7, color = 'gray60')
  )

p2 <- ggplot(cum_df, aes(x = rank)) +
  geom_area(aes(y = revenue_recovered/1000), fill = '#33A02C', alpha = 0.3) +
  geom_line(aes(y = revenue_recovered/1000), color = '#33A02C', linewidth = 1.2) +
  geom_point(data = milestones, aes(y = revenue_recovered/1000), color = '#33A02C', size = 3) +
  scale_x_continuous(breaks = seq(0, 60, 10), limits = c(0, 64)) +
  scale_y_continuous(labels = scales::dollar_format(scale = 1, suffix = 'K')) +
  labs(
    title = 'Cumulative Revenue Recovery',
    subtitle = 'Annual revenue recovered from freed provider time',
    x = 'Top-k Providers Offloaded',
    y = 'Revenue Recovered (Thousands)',
    caption = 'Rate: $173/hour'
  ) +
  theme_minimal(base_size = 10) +
  theme(
    plot.title = element_text(size = 11, face = 'bold'),
    plot.subtitle = element_text(size = 9, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 7, color = 'gray60')
  )

p3 <- ggplot(cum_df, aes(x = rank)) +
  geom_area(aes(y = added_appointments), fill = '#FF7F00', alpha = 0.3) +
  geom_line(aes(y = added_appointments), color = '#FF7F00', linewidth = 1.2) +
  geom_point(data = milestones, aes(y = added_appointments), color = '#FF7F00', size = 3) +
  scale_x_continuous(breaks = seq(0, 60, 10), limits = c(0, 64)) +
  scale_y_continuous(labels = scales::number_format(accuracy = 1)) +
  labs(
    title = 'Additional Appointment Capacity',
    subtitle = 'New appointment slots created through workload optimization',
    x = 'Top-k Providers Offloaded',
    y = 'Additional Appointments',
    caption = 'Based on 30-minute appointments: 2 appts/hour'
  ) +
  theme_minimal(base_size = 10) +
  theme(
    plot.title = element_text(size = 11, face = 'bold'),
    plot.subtitle = element_text(size = 9, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 7, color = 'gray60')
  )

p4 <- ggplot(cum_df, aes(x = rank)) +
  geom_area(aes(y = afterhours_remaining), fill = '#6A3D9A', alpha = 0.3) +
  geom_line(aes(y = afterhours_remaining), color = '#6A3D9A', linewidth = 1.2) +
  geom_point(data = milestones, aes(y = afterhours_remaining), color = '#6A3D9A', size = 3) +
  scale_x_continuous(breaks = seq(0, 60, 10), limits = c(0, 64)) +
  scale_y_continuous(labels = scales::number_format(scale = 1/1000, suffix = 'K')) +
  labs(
    title = 'Remaining After-Hours Work',
    subtitle = 'Reduction in after-hours burden through workload redistribution',
    x = 'Top-k Providers Offloaded',
    y = 'After-Hours Hours Remaining (Thousands)',
    caption = 'Baseline: 3,962 total after-hours hours'
  ) +
  theme_minimal(base_size = 10) +
  theme(
    plot.title = element_text(size = 11, face = 'bold'),
    plot.subtitle = element_text(size = 9, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 7, color = 'gray60')
  )

# Combine all four plots with proper spacing
combined_plot <- (p1 | p2) / (p3 | p4)

# Add overall title and adjust layout
combined_plot <- combined_plot + 
  plot_annotation(
    title = 'Cumulative Impact of In-Basket Workload Redistribution',
    subtitle = 'Department-wide benefits from offloading top providers (July 2024–June 2025)',
    caption = 'Data: Epic Signal Analytics | Analysis: OPC 3535 Market St',
    theme = theme(
      plot.title = element_text(size = 16, face = 'bold', hjust = 0.5),
      plot.subtitle = element_text(size = 12, color = 'gray50', hjust = 0.5),
      plot.caption = element_text(size = 10, color = 'gray60', hjust = 0.5)
    )
  ) &
  theme(plot.margin = margin(10, 10, 10, 10))

print(combined_plot)
```

## Provider Type Performance Comparison

```{r provider-type-comparison}
# Provider type performance comparison
summary_stats <- final |>
  group_by(type) |>
  summarise(
    n = n(),
    mean_hours = mean(inbasket_hours, na.rm = TRUE),
    median_hours = median(inbasket_hours, na.rm = TRUE),
    mean_messages = mean(messages, na.rm = TRUE),
    mean_response_time = mean(avg_dummd, na.rm = TRUE),
    mean_appointments = mean(appointments, na.rm = TRUE),
    mean_system_hours = mean(system_hours, na.rm = TRUE),
    mean_afterhours = mean(afterhours, na.rm = TRUE),
    .groups = 'drop'
  ) |>
  mutate(
    type_label = case_when(
      type == 'MD' ~ 'Attending Psychiatrist',
      type == 'NP' ~ 'Nurse Practitioner', 
      type == 'RF' ~ 'Resident/Fellow'
    )
  )

# Create consistent ordering for all provider type plots
provider_order <- c('Resident/Fellow', 'Attending Psychiatrist', 'Nurse Practitioner')
summary_stats <- summary_stats |>
  mutate(type_label = factor(type_label, levels = provider_order))

# Create provider type comparison plots with consistent ordering
p1_summary <- ggplot(summary_stats, aes(x = type_label, y = mean_hours)) +
  geom_col(aes(fill = type), alpha = 0.8, width = 0.7) +
  geom_text(aes(label = paste0(round(mean_hours, 1), 'h')), 
            hjust = -0.1, size = 4, fontface = 'bold', color = 'black') +
  scale_fill_manual(
    values = c('MD' = '#990000', 'NP' = '#011F5B', 'RF' = '#82AFD3'),
    guide = 'none'
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
  coord_flip() +
  labs(
    title = 'Average In-Basket Hours by Provider Type',
    subtitle = 'Mean workload distribution across provider categories',
    x = 'Provider Type',
    y = 'Average In-Basket Hours',
    caption = 'Higher values indicate greater workload burden'
  ) +
  theme_minimal(base_size = 11) +
  theme(
    plot.title = element_text(size = 12, face = 'bold'),
    plot.subtitle = element_text(size = 10, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 8, color = 'gray60'),
    axis.text = element_text(size = 10)
  )

p2_summary <- ggplot(summary_stats, aes(x = type_label, y = mean_messages)) +
  geom_col(aes(fill = type), alpha = 0.8, width = 0.7) +
  geom_text(aes(label = paste0(round(mean_messages, 0), ' msgs')), 
            hjust = -0.1, size = 4, fontface = 'bold', color = 'black') +
  scale_fill_manual(
    values = c('MD' = '#990000', 'NP' = '#011F5B', 'RF' = '#82AFD3'),
    guide = 'none'
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
  coord_flip() +
  labs(
    title = 'Average Message Volume by Provider Type',
    subtitle = 'Mean message count across provider categories',
    x = 'Provider Type',
    y = 'Average Messages',
    caption = 'Higher values indicate greater message burden'
  ) +
  theme_minimal(base_size = 11) +
  theme(
    plot.title = element_text(size = 12, face = 'bold'),
    plot.subtitle = element_text(size = 10, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 8, color = 'gray60'),
    axis.text = element_text(size = 10)
  )

p3_summary <- ggplot(summary_stats, aes(x = type_label, y = mean_response_time)) +
  geom_col(aes(fill = type), alpha = 0.8, width = 0.7) +
  geom_text(aes(label = paste0(round(mean_response_time, 1), ' days')), 
            hjust = -0.1, size = 4, fontface = 'bold', color = 'black') +
  scale_fill_manual(
    values = c('MD' = '#990000', 'NP' = '#011F5B', 'RF' = '#82AFD3'),
    guide = 'none'
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
  coord_flip() +
  labs(
    title = 'Average Response Time by Provider Type',
    subtitle = 'Mean response time across provider categories',
    x = 'Provider Type',
    y = 'Average Response Time (Days)',
    caption = 'Lower values indicate better responsiveness'
  ) +
  theme_minimal(base_size = 11) +
  theme(
    plot.title = element_text(size = 12, face = 'bold'),
    plot.subtitle = element_text(size = 10, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 8, color = 'gray60'),
    axis.text = element_text(size = 10)
  )

# Combine all summary plots with proper spacing
combined_summary <- p1_summary / p2_summary / p3_summary

# Add proper spacing and layout
combined_summary <- combined_summary + 
  plot_annotation(
    title = 'Provider Type Performance Comparison',
    subtitle = 'Workload and performance metrics across provider categories',
    caption = 'Data: Epic Signal Analytics, OPC 3535 Market St',
    theme = theme(
      plot.title = element_text(size = 14, face = 'bold', hjust = 0.5),
      plot.subtitle = element_text(size = 11, color = 'gray50', hjust = 0.5),
      plot.caption = element_text(size = 9, color = 'gray60', hjust = 0.5)
    )
  ) &
  theme(plot.margin = margin(15, 15, 15, 15))

print(combined_summary)
```

## System Overview Dashboard

```{r system-overview}
# System overview analysis
appointments_by_type <- final |>
  group_by(type) |>
  summarise(appointments = sum(appointments, na.rm = TRUE), .groups = 'drop') |>
  mutate(
    type_label = case_when(
      type == 'MD' ~ 'Attending Psychiatrist',
      type == 'NP' ~ 'Nurse Practitioner',
      type == 'RF' ~ 'Resident/Fellow'
    )
  )

system_hours_total <- sum(final$system_hours, na.rm = TRUE)
inbasket_hours_total <- sum(final$inbasket_hours, na.rm = TRUE)
other_hours_total <- system_hours_total - inbasket_hours_total

# Create consistent ordering for system overview
appointments_by_type <- appointments_by_type |>
  mutate(type_label = factor(type_label, levels = provider_order))

# Create system overview plots with improved positioning
p1_system <- ggplot(appointments_by_type, aes(x = type_label, y = appointments)) +
  geom_col(aes(fill = type), alpha = 0.8, width = 0.7) +
  geom_text(aes(label = scales::comma(appointments)), 
            hjust = -0.1, size = 4, fontface = 'bold', color = 'black') +
  scale_fill_manual(
    values = c('MD' = '#990000', 'NP' = '#011F5B', 'RF' = '#82AFD3'),
    guide = 'none'
  ) +
  scale_y_continuous(labels = scales::comma_format(), 
                     expand = expansion(mult = c(0, 0.3)),
                     limits = c(0, max(appointments_by_type$appointments) * 1.4)) +
  coord_flip() +
  labs(
    title = 'Total Appointments by Provider Type',
    subtitle = paste0('Annual appointment distribution (Total: ', scales::comma(sum(appointments_by_type$appointments)), ')'),
    x = 'Provider Type',
    y = 'Total Appointments',
    caption = 'Data: Epic Signal Analytics, OPC 3535 Market St, July 2024–June 2025'
  ) +
  theme_minimal(base_size = 11) +
  theme(
    plot.title = element_text(size = 12, face = 'bold'),
    plot.subtitle = element_text(size = 10, color = 'gray50'),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 8, color = 'gray60'),
    axis.text = element_text(size = 10)
  )

# System hours breakdown
system_data <- data.frame(
  category = c('Other System Time', 'In-Basket Time'),
  hours = c(other_hours_total, inbasket_hours_total),
  percentage = c(other_hours_total/system_hours_total * 100, inbasket_hours_total/system_hours_total * 100)
)

p2_system <- ggplot(system_data, aes(x = '', y = hours, fill = category)) +
  geom_col(width = 0.8, alpha = 0.8) +
  geom_text(aes(label = paste0(scales::comma(hours), 'h\n(', round(percentage, 1), '%)'),
                color = category), 
            position = position_stack(vjust = 0.5), 
            size = 4, fontface = 'bold') +
  scale_color_manual(values = c('Other System Time' = 'black', 'In-Basket Time' = 'white'), guide = 'none') +
  scale_fill_manual(
    values = c('Other System Time' = '#E0E0E0', 'In-Basket Time' = '#2C7FB8'),
    name = 'System Activity'
  ) +
  coord_polar(theta = 'y') +
  labs(
    title = 'System Hours Distribution',
    subtitle = paste0('Total system time breakdown (Total: ', scales::comma(system_hours_total), ' hours)'),
    x = NULL, y = NULL,
    caption = 'In-basket time represents messaging workload'
  ) +
  theme_void(base_size = 11) +
  theme(
    plot.title = element_text(size = 12, face = 'bold', hjust = 0.5),
    plot.subtitle = element_text(size = 10, color = 'gray50', hjust = 0.5),
    plot.caption = element_text(size = 8, color = 'gray60', hjust = 0.5),
    legend.position = 'bottom',
    legend.text = element_text(size = 10)
  )

# Combine the system overview plots with proper spacing
system_overview <- p1_system | p2_system

# Add proper spacing and layout
system_overview <- system_overview + 
  plot_annotation(
    title = 'System Overview Dashboard',
    subtitle = 'Provider activity and system utilization metrics',
    caption = 'Data: Epic Signal Analytics, OPC 3535 Market St, July 2024–June 2025',
    theme = theme(
      plot.title = element_text(size = 14, face = 'bold', hjust = 0.5),
      plot.subtitle = element_text(size = 11, color = 'gray50', hjust = 0.5),
      plot.caption = element_text(size = 9, color = 'gray60', hjust = 0.5)
    )
  ) &
  theme(plot.margin = margin(15, 15, 15, 15))

print(system_overview)
```

# Discussion

## Key Findings Summary

The analysis reveals significant workload disparities in Epic in-basket messaging across the Department of Psychiatry. The **5,044× variation** in workload between the highest and lowest providers represents a substantial operational inefficiency that presents both challenges and opportunities.

### Workload Distribution

The Lorenz curve analysis demonstrates substantial inequality in workload distribution, with a **Gini coefficient of 0.494**, indicating significant concentration of messaging burden among a subset of providers. The bottom 50% of providers handle only 20% of the total in-basket workload, while the top 10% handle 33% of all messaging.

### Provider Type Differences

Attending psychiatrists demonstrate the highest mean in-basket hours (38.2 hours), followed by nurse practitioners (25.1 hours) and residents/fellows (19.8 hours). However, the variation within each provider type is substantial, suggesting that individual factors beyond provider type significantly influence workload.

### Message Type Analysis

Medical advice requests constitute the largest proportion of in-basket messages (42.3%), followed by patient calls (28.1%), results (16.2%), and prescription authorizations (13.4%). This distribution suggests that most messaging burden stems from direct patient care activities rather than administrative tasks.

## Financial Metrics

The analysis calculates financial metrics associated with in-basket messaging workload. The **$335,828 potential annual revenue loss** from in-basket work (extrapolated from 12-month data) represents 1.04 FTE equivalent of provider time.

### Top 10 Providers Financial Analysis

A financial analysis focusing on the top 10 providers shows a **121.8% return on investment** calculation. The $78,950 potential net annual benefit calculation is based on workload redistribution scenarios for in-basket messaging management (extrapolated from 12-month data).

### Key Capacity and Efficiency Metrics

The cumulative impact analysis reveals significant potential for capacity expansion and efficiency improvements:

- **Additional Appointment Capacity**: Workload redistribution could create substantial new appointment slots based on 30-minute appointments (2 appointments per hour)
- **After-Hours Work Reduction**: Current baseline of 3,962 total after-hours hours could be significantly reduced through strategic provider offloading
- **FTE Recovery**: Up to 1.04 FTE equivalent could be freed through workload optimization
- **Revenue Recovery**: Potential to recover up to $335,828 in annual revenue through provider time reallocation (extrapolated from 12-month data)

## Limitations

Several limitations should be considered when interpreting these results:

1. **Temporal Scope**: The analysis covers a 12-month period and may not capture seasonal variations or long-term trends.
2. **Causality**: The analysis identifies correlations but cannot establish causal relationships between workload factors and outcomes.
3. **Provider Characteristics**: Individual provider factors (experience, specialty, patient population) may influence workload beyond what is captured in the current metrics.
4. **System Factors**: Epic system configuration and institutional policies may affect workload distribution independently of provider characteristics.

## Observations

### Workload Patterns

The data shows concentration of messaging workload among a subset of providers, with the top 10 highest-volume providers handling a disproportionate share of in-basket messages.

### Resource Utilization

The analysis reveals patterns in how provider time is allocated between direct patient care activities and administrative messaging tasks.

### System Characteristics

The Epic Signal Analytics data demonstrates variability in provider engagement with the messaging system across different provider types and individual providers.

# Summary

This comprehensive analysis of Epic in-basket messaging workload describes patterns and characteristics across the Outpatient Psychiatry Clinic (OPC) at 3535 Market St, second floor. The **160× variation** in workload across providers represents a substantial difference in provider engagement with the messaging system.

The financial analysis calculates potential returns associated with workload redistribution scenarios, with calculations showing **121.8% ROI** and **$78,950 potential net annual benefit** (extrapolated from 12-month data). These findings describe the financial characteristics of the current messaging workload distribution.

The data presented here provides a descriptive foundation for understanding Epic in-basket messaging patterns and their associated resource utilization characteristics in the Outpatient Psychiatry Clinic (OPC) at 3535 Market St, second floor.

---

**Data Source**: Epic Signal Analytics, Penn Medicine Health System  
**Analysis Period**: July 2024 – June 2025  
**Location**: Outpatient Psychiatry Clinic (OPC), 3535 Market St, 2nd Floor, Penn Medicine
**Course**: BMIN 5070 – Human Factors in Biomedical Informatics  
**Institution**: University of Pennsylvania, Perelman School of Medicine
